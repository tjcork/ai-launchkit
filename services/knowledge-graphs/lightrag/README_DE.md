# üîó LightRAG - Graph-basiertes RAG mit automatischer Entit√§tsextraktion

### Was ist LightRAG?

LightRAG ist ein graph-basiertes RAG-System (Retrieval-Augmented Generation), das automatisch Entit√§ten und Beziehungen aus Dokumenten extrahiert und in einem Wissensgraphen speichert. Im Gegensatz zu traditionellem Vektor-RAG, das nur nach semantischer √Ñhnlichkeit sucht, versteht LightRAG **Beziehungen zwischen Konzepten** und kann komplexe Abfragen beantworten, die Kontext √ºber mehrere Entit√§ten hinweg erfordern. Perfekt f√ºr Unternehmens-Dokumentation, Forschungsarbeiten und komplexe Wissensbasen.

### Features

- **üï∏Ô∏è Automatische Wissensgraph-Erstellung**: Extrahiert automatisch Entit√§ten und Beziehungen aus Text
- **üéØ Multi-Modus-Abfragen**: Local (spezifisch), Global (√úberblick), Hybrid (kombiniert), Naive (einfach)
- **üß† Beziehungsbewusstes Abrufen**: Findet Verbindungen zwischen Konzepten, nicht nur √§hnliche Texte
- **üîÑ Inkrementelle Updates**: F√ºgt neue Dokumente zum bestehenden Graph hinzu ohne Neuaufbau
- **‚ö° Schnelle Graph-Abfragen**: Optimiert f√ºr schnelles Durchlaufen gro√üer Wissensgraphen
- **üé® Visuelle Graph-Exploration**: Optionales Neo4j-Backend f√ºr Visualisierung
- **üåê Multiple LLM-Unterst√ºtzung**: Ollama (lokal, Standard), OpenAI (schneller) oder andere

### Initiales Setup

**Erster Zugriff auf LightRAG:**

1. **Zugriff √ºber Web-UI:**
```
https://lightrag.deinedomain.com
```
Einfache UI zum Dokumenten-Upload und Abfragen.

2. **API-Health testen:**
```bash
curl http://lightrag:9621/health
# Sollte zur√ºckgeben: {"status": "healthy"}
```

3. **Erstes Dokument einf√ºgen:**
```bash
curl -X POST http://lightrag:9621/api/insert \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Alice arbeitet bei TechCorp als Software-Ingenieurin. Bob ist der CEO von TechCorp. Charlie kennt Alice von der Universit√§t.",
    "metadata": {"source": "test_dokument"}
  }'
```

LightRAG extrahiert automatisch:
- **Entit√§ten**: Alice (Person), Bob (Person), Charlie (Person), TechCorp (Firma)
- **Beziehungen**: Alice-ARBEITET_BEI‚ÜíTechCorp, Bob-CEO_VON‚ÜíTechCorp, Charlie-KENNT‚ÜíAlice

4. **Den Wissensgraphen abfragen:**
```bash
curl -X POST http://lightrag:9621/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Wer arbeitet bei TechCorp?",
    "mode": "local"
  }'
```

### Abfrage-Modi erkl√§rt

LightRAG bietet 4 verschiedene Abfrage-Modi f√ºr unterschiedliche Anwendungsf√§lle:

| Modus | Anwendungsfall | Funktionsweise | Am besten f√ºr |
|------|----------|--------------|----------|
| **`local`** | Spezifische Entit√§ts-Information | Sucht nach direkten Entit√§tsbeziehungen | "Was ist Alices Rolle?" |
| **`global`** | High-Level-√úberblick | Analysiert den gesamten Wissensgraphen | "Was sind die Hauptthemen?" |
| **`hybrid`** | Kombinierte Analyse | Kombiniert local + global | "Wie setzt TechCorp SDGs um?" |
| **`naive`** | Einfache Stichwortsuche | Traditionelle Vektor-√Ñhnlichkeit | "Finde 'Nachhaltigkeit'" |

**Modus-Vergleich Beispiele:**

```javascript
// Local-Modus - Spezifische Entit√§ts-Information
{
  "query": "Was ist die Rolle von Petra Hedorfer?",
  "mode": "local",
  "max_results": 5
}
// Gibt zur√ºck: Direkte Informationen √ºber Petra und ihre unmittelbaren Beziehungen

// Global-Modus - High-Level-Zusammenfassungen
{
  "query": "Was sind die Hauptnachhaltigkeitsinitiativen?",
  "mode": "global",
  "max_results": 10
}
// Gibt zur√ºck: √úbergreifende Themen und Muster √ºber alle Dokumente

// Hybrid-Modus - Kombiniert beide Ans√§tze (EMPFOHLEN)
{
  "query": "Wie setzt DZT SDGs im Tourismus um?",
  "mode": "hybrid",
  "stream": false
}
// Gibt zur√ºck: Spezifische Beispiele + √ºbergeordneter Kontext

// Naive-Modus - Einfache Stichwortsuche
{
  "query": "Nachhaltigkeitsberichte",
  "mode": "naive"
}
// Gibt zur√ºck: Dokumente, die mit Stichworten √ºbereinstimmen (kein Graph-Reasoning)
```

### API-Zugriff

LightRAG l√§uft als interner Service, der f√ºr andere Container zug√§nglich ist:

**Interner API-Endpunkt:**
```
http://lightrag:9621
```

**Wichtige API-Endpunkte:**
- `POST /api/insert` - Dokument einf√ºgen und Entit√§ten extrahieren
- `POST /api/query` - Wissensgraphen abfragen
- `GET /api/health` - Health-Check
- `DELETE /api/clear` - Wissensgraphen l√∂schen (mit Vorsicht verwenden!)

### n8n Integration Setup

LightRAG hat keinen nativen n8n-Node - Integration erfolgt √ºber HTTP Request Nodes.

**Interne URL:** `http://lightrag:9621`

**Keine Zugangsdaten erforderlich** f√ºr interne Container-zu-Container-Kommunikation.

### Beispiel-Workflows

#### Beispiel 1: Wissensgraph aus Dokumenten erstellen

Automatisch Wissensgraph aus hochgeladenen PDFs erstellen.

**Workflow-Struktur:**
1. **Google Drive Trigger** - Ordner auf neue PDFs √ºberwachen
   ```javascript
   Folder: /Documents/KnowledgeBase
   Dateityp: PDF
   ```

2. **Read Binary File** - PDF-Inhalt abrufen

3. **HTTP Request** - Text aus PDF extrahieren
   ```javascript
   Methode: POST
   URL: http://gotenberg:3000/forms/pdfengines/convert
   // Oder nutze einen anderen PDF-zu-Text-Service
   ```

4. **Code Node - In Chunks aufteilen**
   ```javascript
   const text = $input.item.json.text;
   const chunkSize = 3000;  // Zeichen pro Chunk
   const chunks = [];
   
   for (let i = 0; i < text.length; i += chunkSize) {
     chunks.push({
       text: text.substring(i, i + chunkSize),
       chunk_index: Math.floor(i / chunkSize)
     });
   }
   
   return chunks.map(c => ({ json: c }));
   ```

5. **Loop Node** - Jeden Chunk verarbeiten

6. **HTTP Request - In LightRAG einf√ºgen**
   ```javascript
   Methode: POST
   URL: http://lightrag:9621/api/insert
   Header:
     Content-Type: application/json
   Body: {
     "text": "{{ $json.text }}",
     "metadata": {
       "source": "{{ $('Google Drive Trigger').item.json.name }}",
       "chunk_index": {{ $json.chunk_index }},
       "timestamp": "{{ $now.toISO() }}"
     }
   }
   
   // LightRAG f√ºhrt automatisch aus:
   // - Extrahiert Entit√§ten (Personen, Firmen, Konzepte)
   // - Identifiziert Beziehungen
   // - Baut Wissensgraph auf
   // - Erstellt Embeddings
   ```

7. **Wait Node**
   ```javascript
   Duration: 2 seconds  // Zeit f√ºr Verarbeitung geben
   ```

8. **Aggregate Results**
   ```javascript
   const processedChunks = $input.all().length;
   const document = $('Google Drive Trigger').item.json.name;
   
   return [{
     json: {
       document: document,
       chunks_processed: processedChunks,
       knowledge_graph_updated: true
     }
   }];
   ```

9. **Slack Notification**
   ```javascript
   Nachricht: |
     üìö Wissensgraph aktualisiert
     
     Dokument: {{ $json.document }}
     Chunks verarbeitet: {{ $json.chunks_processed }}
     
     Frage deinen Wissensgraphen ab unter https://lightrag.deinedomain.com
   ```

**Anwendungsfall**: Automatischer Aufbau einer Wissensbasis aus Unternehmens-Dokumentation.

#### Beispiel 2: Intelligente Dokumenten-Q&A

Fragen mit graph-basiertem Verst√§ndnis beantworten.

**Workflow-Struktur:**
1. **Webhook Trigger**
   ```javascript
   Input: {
     "question": "Was sind die Hauptnachhaltigkeitsinitiativen von TechCorp und wer leitet sie?",
     "query_mode": "hybrid"
   }
   ```

2. **HTTP Request - LightRAG abfragen**
   ```javascript
   Methode: POST
   URL: http://lightrag:9621/api/query
   Header:
     Content-Type: application/json
   Body: {
     "query": "{{ $json.question }}",
     "mode": "{{ $json.query_mode }}",
     "max_results": 5,
     "stream": false
   }
   
   // Antwort enth√§lt:
   {
     "answer": "Umfassende Antwort basierend auf Graph-Reasoning...",
     "entities": ["TechCorp", "Nachhaltigkeitsinitiative X", "Alice Smith"],
     "relationships": [
       {"from": "Alice Smith", "type": "LEITET", "to": "Nachhaltigkeitsinitiative X"},
       {"from": "Nachhaltigkeitsinitiative X", "type": "TEIL_VON", "to": "TechCorp"}
     ],
     "sources": [
       {"document": "Jahresbericht 2024", "relevance": 0.95}
     ]
   }
   ```

3. **Code Node - Antwort mit Graph-Kontext formatieren**
   ```javascript
   const answer = $input.item.json.answer;
   const entities = $input.item.json.entities || [];
   const relationships = $input.item.json.relationships || [];
   const sources = $input.item.json.sources || [];
   
   const formattedResponse = `
   **Antwort:**
   ${answer}
   
   **Schl√ºssel-Entit√§ten:**
   ${entities.map(e => `- ${e}`).join('\n')}
   
   **Gefundene Beziehungen:**
   ${relationships.map(r => `- ${r.from} ${r.type} ${r.to}`).join('\n')}
   
   **Quellen:**
   ${sources.map((s, i) => `${i+1}. ${s.document} (Relevanz: ${(s.relevance * 100).toFixed(0)}%)`).join('\n')}
   `;
   
   return [{
     json: {
       question: $('Webhook').item.json.question,
       response: formattedResponse,
       entities: entities,
       sources: sources
     }
   }];
   ```

4. **Antwort senden** - E-Mail, Slack oder API-Antwort

**Anwendungsfall**: Interner Wissensbasis-Assistent, Kundensupport-Automatisierung.

#### Beispiel 3: Naive vs. Graph-basiertes RAG vergleichen

Demonstriere die Leistungsf√§higkeit von graph-basiertem Reasoning.

**Workflow-Struktur:**
1. **Manual Trigger**
   ```javascript
   Input: {
     "question": "Was ist die Verbindung zwischen Alice und dem Nachhaltigkeitsprojekt?"
   }
   ```

2. **Split in Batches** - Parallele Abfragen ausf√ºhren

3a. **HTTP Request - Naive RAG** (stichwort-basiert)
   ```javascript
   Methode: POST
   URL: http://lightrag:9621/api/query
   Body: {
     "query": "{{ $json.question }}",
     "mode": "naive"
   }
   ```

3b. **HTTP Request - Graph-basiertes RAG** (beziehungsbewusst)
   ```javascript
   Methode: POST
   URL: http://lightrag:9621/api/query
   Body: {
     "query": "{{ $json.question }}",
     "mode": "hybrid"
   }
   ```

4. **Aggregate & Compare**
   ```javascript
   const naiveAnswer = $item(0).json.answer;
   const graphAnswer = $item(1).json.answer;
   
   return [{
     json: {
       question: $('Manual Trigger').item.json.question,
       naive_rag: {
         answer: naiveAnswer,
         method: "Einfaches Stichwort-Matching"
       },
       graph_rag: {
         answer: graphAnswer,
         method: "Beziehungsdurchlauf + semantisches Verst√§ndnis",
         entities: $item(1).json.entities,
         relationships: $item(1).json.relationships
       },
       winner: graphAnswer.length > naiveAnswer.length ? "Graph RAG" : "Naive RAG"
     }
   }];
   
   // Typische Ergebnisse:
   // Naive: "Alice wird in Nachhaltigkeitsdokumenten erw√§hnt."
   // Graph: "Alice leitet das Green Initiative-Projekt, das Teil von TechCorps 
   //         Nachhaltigkeitsbem√ºhungen ist. Sie berichtet an Bob, den CEO, und arbeitet 
   //         mit dem Umwelt-Team zusammen."
   ```

**Anwendungsfall**: √úberlegenheit von graph-basiertem RAG f√ºr Beziehungsabfragen demonstrieren.

### Open WebUI Integration

**LightRAG als Chat-Modell in Open WebUI hinzuf√ºgen:**

LightRAG kann direkt in Open WebUI als Ollama-kompatibles Modell integriert werden!

**Setup-Schritte:**
1. **Open WebUI Einstellungen ‚Üí Verbindungen**
2. **Neue Ollama-Verbindung hinzuf√ºgen:**
   - **URL:** `http://lightrag:9621`
   - **Modellname:** `lightrag:latest`
3. **LightRAG aus dem Modell-Dropdown im Chat ausw√§hlen**

**Jetzt kannst du direkt mit deinem Wissensgraphen chatten!**

Dies erm√∂glicht:
- Nat√ºrliche Unterhaltung mit dem Wissensgraphen
- Automatische Entit√§ts- und Beziehungserkennung
- Graph-basierte Antworten anstelle von nur Vektorsuche
- Visualisierung von Entit√§tsbeziehungen

### Von Ollama zu OpenAI wechseln (Optional)

LightRAG nutzt standardm√§√üig lokale Ollama-Modelle. F√ºr bessere Performance mit gro√üen Dokumenten wechsle zu OpenAI:

**Warum zu OpenAI wechseln?**
- ‚ö° **10-100x schneller** als CPU-basiertes Ollama
- üìÑ **Gro√üe Dokumente**: PDFs mit 50+ Seiten ohne Timeouts verarbeiten
- üéØ **Bessere Qualit√§t**: Genauere Entit√§ts- und Beziehungsextraktion
- üí∞ **Kosteneffizient**: gpt-4o-mini kostet ~$0.15 pro Million Tokens

**Konfigurations-Schritte:**

1. **OpenAI API Key zu .env hinzuf√ºgen:**
```bash
cd /root/ai-corekit
nano .env

# Hinzuf√ºgen oder aktualisieren:
OPENAI_API_KEY=sk-proj-DEIN-API-KEY-HIER
```

2. **docker-compose.yml aktualisieren:**
```yaml
lightrag:
  environment:
    - OPENAI_API_KEY=${OPENAI_API_KEY}
    - LLM_BINDING=openai                           # Ge√§ndert von ollama
    - LLM_BINDING_HOST=https://api.openai.com/v1   # OpenAI Endpunkt
    - LLM_MODEL=gpt-4o-mini                        # Kosteneffizientes Modell
    - EMBEDDING_BINDING=openai                     # Ge√§ndert von ollama
    - EMBEDDING_BINDING_HOST=https://api.openai.com/v1
    - EMBEDDING_MODEL=text-embedding-3-small       # OpenAI Embeddings
    - EMBEDDING_DIM=1536                           # OpenAI Dimension (nicht 768!)
```

3. **LightRAG neu starten:**
```bash
corekit restart lightrag
```

**Performance-Vergleich:**

| Metrik | Ollama (CPU) | OpenAI API |
|--------|--------------|------------|
| Entit√§tsextraktion (10-Seiten-PDF) | 2-5 Minuten | 10-30 Sekunden |
| Abfrage-Antwort | 5-15 Sekunden | 1-3 Sekunden |
| Kosten (1M Tokens) | Kostenlos (lokal) | ~$0.15-0.60 |
| Qualit√§t | Gut | Exzellent |

### Fehlerbehebung

**Problem 1: Langsame Entit√§tsextraktion**

```bash
# Pr√ºfen ob Ollama (langsam) oder OpenAI (schnell) verwendet wird
corekit logs lightrag | grep -E "LLM_BINDING|EMBEDDING_BINDING"

# Falls Ollama auf CPU verwendet wird:
# L√∂sung 1: Zu OpenAI wechseln (siehe oben)
# L√∂sung 2: Kleinere Dokumente verwenden (< 5 Seiten auf einmal)
# L√∂sung 3: Chunk-Gr√∂√üe im Preprocessing reduzieren

# Pr√ºfen ob Ollama l√§uft
corekit ps | grep ollama
curl http://ollama:11434/api/tags
```

**L√∂sung:**
- Zu OpenAI f√ºr Produktionslasten wechseln
- Dokumente in kleineren Batches verarbeiten
- `hybrid`-Modus anstelle von `global` f√ºr schnellere Abfragen verwenden

**Problem 2: Abfrage gibt keine Ergebnisse zur√ºck**

```bash
# Pr√ºfen ob Dokumente eingef√ºgt wurden
curl http://lightrag:9621/api/health

# Wissensgraphen auf Daten verifizieren
corekit logs lightrag | grep "entities extracted"

# Mit einfacher Abfrage testen
curl -X POST http://lightrag:9621/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "mode": "naive"}'
```

**L√∂sung:**
- Wissensgraph k√∂nnte leer sein - Dokumente erneut einf√ºgen
- Zuerst `naive`-Modus versuchen, um zu pr√ºfen ob Dokumente existieren
- Pr√ºfen ob Entit√§ten tats√§chlich extrahiert wurden (Logs anzeigen)

**Problem 3: Authentifizierungsfehler in Open WebUI**

```bash
# Pr√ºfen ob LightRAG-Port erreichbar ist
corekit exec open-webui curl http://lightrag:9621/health

# Ollama-kompatible API verifizieren
curl http://lightrag:9621/v1/models
# Sollte Modellliste zur√ºckgeben

# Open WebUI neu starten
corekit restart open-webui
```

**L√∂sung:**
- Interne DNS-Aufl√∂sung zwischen Containern verifizieren
- Docker-Netzwerk pr√ºfen: `docker network inspect ai-corekit_default`
- Sicherstellen, dass LightRAG-Container l√§uft

**Problem 4: Zu wenig Speicher-Fehler**

```bash
# Speichernutzung pr√ºfen
docker stats lightrag --no-stream

# LightRAG kann mit gro√üen Graphen speicherintensiv sein
```

**L√∂sung:**
- Docker-Speicherlimit in `docker-compose.yml` erh√∂hen:
  ```yaml
  lightrag:
    deploy:
      resources:
        limits:
          memory: 4G  # Von 2G erh√∂hen
  ```
- Alten Wissensgraphen l√∂schen: `curl -X DELETE http://lightrag:9621/api/clear`
- OpenAI anstelle von Ollama verwenden (weniger RAM ben√∂tigt)

**Problem 5: Container startet nicht**

```bash
# Container-Status pr√ºfen
corekit ps -a | grep lightrag

# Logs anzeigen
corekit logs lightrag

# H√§ufige Probleme:
# - Fehlende LLM-Konfiguration
# - Ollama l√§uft nicht
# - Port 9621 bereits in Verwendung
```

**L√∂sung:**
- Verifizieren, dass Ollama l√§uft: `docker ps | grep ollama`
- Port-Konflikte pr√ºfen: `netstat -tulpn | grep 9621`
- Mit Abh√§ngigkeiten neu starten: `corekit restart ollama lightrag`

### Best Practices

**Dokumenten-Verarbeitung:**
- **Chunk-Gr√∂√üe**: 2000-4000 Zeichen f√ºr optimale Entit√§tsextraktion
- **√úberlappung**: Nicht erforderlich (LightRAG verarbeitet Kontext intern)
- **Metadaten**: Immer Quelle, Zeitstempel, Dokumenttyp einbeziehen
- **Inkrementelle Updates**: Neue Dokumente kontinuierlich einf√ºgen, kein Neuaufbau erforderlich

**Abfrage-Optimierung:**
- **`hybrid`-Modus verwenden** f√ºr die meisten Abfragen (beste Balance)
- **`local`-Modus verwenden** f√ºr spezifische Entit√§tsfragen
- **`global`-Modus verwenden** f√ºr √úberblick/Zusammenfassungsfragen
- **`naive`-Modus verwenden** nur f√ºr einfache Stichwortsuchen

**Entit√§tsextraktions-Qualit√§t:**
- **OpenAI verwenden** f√ºr Produktion (10x besser als Ollama)
- **Dokumente vorverarbeiten**: Kopf-/Fu√üzeilen entfernen, Formatierung bereinigen
- **Dom√§nenspezifische Prompts**: Entit√§tstypen bei Bedarf anpassen
- **Extraktionen validieren**: Beispiel-Entit√§ten nach erstem Batch √ºberpr√ºfen

**Performance-Tipps:**
- Dokumente in **Batches von 10-20** gleichzeitig verarbeiten
- **Parallele Verarbeitung** in n8n f√ºr gro√üe Dokumentensets verwenden
- **H√§ufige Abfragen cachen** in Redis oder PostgreSQL
- **Graph-Gr√∂√üe √ºberwachen**: Gro√üe Graphen (>100K Entit√§ten) ben√∂tigen m√∂glicherweise Optimierung

**Integrations-Muster:**

```javascript
// Muster 1: RAG-Pipeline
Dokumenten-Upload ‚Üí LightRAG Insert ‚Üí Abfrage mit Kontext

// Muster 2: Hybrid-Suche
LightRAG (graph-basiert) + Qdrant (vektor-basiert) ‚Üí Ergebnisse kombinieren

// Muster 3: Entit√§ts-Anreicherung
Entit√§ten mit LightRAG extrahieren ‚Üí Mit externen APIs anreichern ‚Üí Graph aktualisieren

// Muster 4: Wissensgraph-Visualisierung
LightRAG (Speicherung) ‚Üí Export zu Neo4j (Visualisierung)
```

### Ressourcen

- **Offizielle Dokumentation**: https://github.com/HKUDS/LightRAG
- **GitHub Repository**: https://github.com/HKUDS/LightRAG
- **Forschungsarbeit**: [LightRAG: Simple and Fast Retrieval-Augmented Generation](https://arxiv.org/abs/2410.05779)
- **Web-UI**: `https://lightrag.deinedomain.com`
- **Interne API**: `http://lightrag:9621`
- **OpenAPI Docs**: `http://lightrag:9621/docs`

**Verwandte Services:**
- Mit **Neo4j** verwenden f√ºr Graph-Visualisierung
- Kombinieren mit **Qdrant/Weaviate** f√ºr hybride Vektor+Graph-Suche
- Dokumente mit **Gotenberg** verarbeiten (PDF zu Text)
- Aus **Open WebUI** abfragen f√ºr konversationelle Schnittstelle
- Mit **Ollama** (lokal) oder **OpenAI** (schnell) analysieren
