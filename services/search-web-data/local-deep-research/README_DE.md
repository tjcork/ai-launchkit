# üî¨ Local Deep Research - Iterative Recherche mit Reflexion

### Was ist Local Deep Research?

Local Deep Research ist LangChains iteratives Tiefenrecherche-Tool, das ~95% Genauigkeit durch Recherche-Schleifen mit Reflexion und Selbstkritik erreicht. Im Gegensatz zu einfachen Web-Suchen f√ºhrt Local Deep Research mehrere Iterationen durch, validiert Informationen gegen mehrere Quellen, identifiziert Widerspr√ºche und verfeinert kontinuierlich Ergebnisse. Perfekt f√ºr Faktenpr√ºfung, detaillierte Analysen und Situationen, die h√∂chste Genauigkeit erfordern.

Das Tool nutzt einen iterativen Ansatz: es recherchiert, reflektiert √ºber das Gefundene, identifiziert L√ºcken oder Inkonsistenzen und f√ºhrt dann zus√§tzliche Recherchen durch, um diese L√ºcken zu f√ºllen - wiederholt bis das Vertrauen hoch ist oder das Iterations-Limit erreicht wird.

### Features

- **üéØ H√∂chste Genauigkeit**: ~95% Genauigkeit durch iterative Validierung und Reflexion
- **üîÑ Recherche-Schleifen**: Mehrere Recherche-Durchg√§nge mit kontinuierlicher Verfeinerung
- **üß† Selbst-Reflexion**: Identifiziert L√ºcken, Widerspr√ºche und unzureichende Informationen
- **‚úÖ Faktenpr√ºfung**: Multi-Quellen-Validierung f√ºr maximale Zuverl√§ssigkeit
- **üìä Konfidenz-Scoring**: Jede Aussage mit Konfidenz-Score und Quellenangaben
- **üåê Multi-Such-Backend**: Unterst√ºtzt SearXNG, Tavily und andere Suchmaschinen
- **‚è±Ô∏è Tiefenanalyse**: 10-20 Minuten f√ºr umfassende Recherche (vs. 2-5 Min f√ºr GPT Researcher)

### Ersteinrichtung

**Erster Zugriff auf Local Deep Research:**

1. **API-Gesundheit testen:**
```bash
curl http://local-deep-research:2024/health
# Sollte zur√ºckgeben: {"status": "healthy", "version": "1.0"}
```

2. **Einfache Recherche starten:**
```bash
curl -X POST http://local-deep-research:2024/api/research \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Is quantum computing viable for commercial use in 2025?",
    "iterations": 3
  }'
```

Antwort enth√§lt `task_id` und `websocket_url` f√ºr Echtzeit-Updates.

3. **Recherche-Fortschritt pr√ºfen:**
```bash
curl http://local-deep-research:2024/api/status/{task_id}
```

4. **WebSocket f√ºr Live-Updates (Optional):**
```bash
wscat -c ws://local-deep-research:2024/ws/{task_id}
# Echtzeit-Fortschritt-Updates empfangen
```

**Wichtig:** Local Deep Research l√§uft nur intern (keine HTTPS-Subdomain) f√ºr n8n/interne Services.

### API-Zugriff

Local Deep Research l√§uft als interner Service, der f√ºr andere Container zug√§nglich ist:

**Interner API-Endpunkt:**
```
http://local-deep-research:2024
```

**Wichtige API-Endpunkte:**
- `POST /api/research` - Iterative Recherche starten
- `POST /api/verify` - Spezifische Behauptung faktenpr√ºfen
- `GET /api/status/{task_id}` - Fortschritt pr√ºfen
- `GET /api/result/{task_id}` - Finale Analyse abrufen
- `GET /health` - Service-Gesundheitspr√ºfung

### n8n-Integrationssetup

Local Deep Research hat keinen nativen n8n-Node - Integration erfolgt √ºber HTTP-Request-Nodes.

**Interne URL:** `http://local-deep-research:2024`

**Keine Credentials erforderlich** f√ºr interne Container-zu-Container-Kommunikation.

### Beispiel-Workflows

#### Beispiel 1: Hochgenaue Faktenpr√ºfung

Behauptungen mit Multi-Quellen-Validierung und Reflexion verifizieren.

**Workflow-Struktur:**
1. **Webhook/Manueller Trigger**
   ```javascript
   Input: {
     "claim": "Quantum computers can break RSA-2048 encryption today",
     "confidence_required": 0.9
   }
   ```

2. **HTTP Request Node - Faktencheck mit Local Deep Research**
   ```javascript
   Methode: POST
   URL: http://local-deep-research:2024/api/verify
   Header:
     Content-Type: application/json
   Body: {
     "statement": "{{ $json.claim }}",
     "confidence_threshold": {{ $json.confidence_required }},
     "sources_required": 3,
     "iterations": 5
   }
   
   // Antwort: { "task_id": "xyz-789", "websocket_url": "ws://..." }
   ```

3. **Wait Node**
   ```javascript
   Duration: 300 seconds  // 5 Minuten f√ºr Tiefenanalyse
   ```

4. **Code Node - Auf Fertigstellung pollen**
   ```javascript
   const taskId = $('HTTP Request').item.json.task_id;
   const maxAttempts = 20;
   let attempts = 0;
   
   while (attempts < maxAttempts) {
     const status = await $http.request({
       method: 'GET',
       url: `http://local-deep-research:2024/api/status/${taskId}`
     });
     
     if (status.status === 'completed') {
       return { taskId, ready: true };
     }
     
     if (status.status === 'failed') {
       throw new Error('Research failed: ' + status.error);
     }
     
     // 30 Sekunden zwischen Checks warten
     await new Promise(resolve => setTimeout(resolve, 30000));
     attempts++;
   }
   
   throw new Error('Research timeout after 10 minutes');
   ```

5. **HTTP Request Node - Verifizierungs-Ergebnis abrufen**
   ```javascript
   Methode: GET
   URL: http://local-deep-research:2024/api/result/{{ $json.taskId }}
   ```

6. **Code Node - Verifizierung parsen**
   ```javascript
   const result = $input.item.json;
   
   return [{
     json: {
       claim: $('Webhook').item.json.claim,
       verdict: result.verified ? 'TRUE' : 'FALSE',
       confidence: result.confidence_score,
       reasoning: result.reasoning,
       sources: result.sources,
       contradictions: result.contradictions_found || [],
       iterations_used: result.iterations_completed,
       warnings: result.warnings || []
     }
   }];
   ```

7. **IF Node - Konfidenz pr√ºfen**
   ```javascript
   Bedingung: {{ $json.confidence }} >= {{ $('Webhook').item.json.confidence_required }}
   ```

8. **Action Nodes**
   - **Hohe Konfidenz-Pfad**: Ergebnis akzeptieren und speichern
   - **Niedrige Konfidenz-Pfad**: An menschliche √úberpr√ºfung mit allen Quellen eskalieren

**Anwendungsfall**: Marketing-Behauptungen verifizieren, Statistiken f√ºr Berichte validieren, Artikel faktenpr√ºfen.

#### Beispiel 2: Kombinierte Schnell + Tief-Recherche-Strategie

GPT Researcher f√ºr √úberblick, Local Deep Research f√ºr Genauigkeits-Verifizierung nutzen.

**Workflow-Struktur:**
1. **Webhook Trigger**
   ```javascript
   Input: { 
     "topic": "Impact of AI regulation on European startups",
     "depth": "comprehensive"
   }
   ```

2. **GPT Researcher - Schnelle √úbersicht (3 Minuten)**
   ```javascript
   Methode: POST
   URL: http://gpt-researcher:8000/api/research
   Body: {
     "query": "{{ $json.topic }}",
     "report_type": "outline_report",
     "max_iterations": 3
   }
   ```

3. **Wait + GPT Researcher Ergebnisse abrufen**

4. **Code Node - Kernbehauptungen extrahieren**
   ```javascript
   const report = $json.report;
   
   // Fettgedruckte Aussagen, Statistiken, Vorhersagen extrahieren
   const claimPatterns = [
     /\d+%/g,  // Prozentzahlen
     /\$[\d,]+/g,  // Dollar-Betr√§ge
     /by \d{4}/gi,  // Jahres-Vorhersagen
     /research shows/gi,  // Recherche-Behauptungen
     /studies indicate/gi  // Studien-Referenzen
   ];
   
   const claims = [];
   for (const pattern of claimPatterns) {
     const matches = report.match(pattern);
     if (matches) {
       // S√§tze extrahieren, die diese Muster enthalten
       matches.forEach(match => {
         const sentences = report.split(/[.!?]/);
         const claimSentences = sentences.filter(s => s.includes(match));
         claims.push(...claimSentences.map(s => s.trim()));
       });
     }
   }
   
   // Eindeutige Behauptungen zur√ºckgeben
   return [...new Set(claims)].map(claim => ({ json: { claim } }));
   ```

5. **Loop Over Claims**

6. **HTTP Request - Jede Behauptung verifizieren (Innerhalb Loop)**
   ```javascript
   Methode: POST
   URL: http://local-deep-research:2024/api/verify
   Body: {
     "statement": "{{ $json.item.claim }}",
     "context": "{{ $('GPT Researcher').json.report.substring(0, 1000) }}",
     "iterations": 3,
     "confidence_threshold": 0.8
   }
   ```

7. **Wait + Poll + Ergebnisse abrufen** (wie in Beispiel 1)

8. **Aggregate Node - Verifizierten Bericht kompilieren**
   ```javascript
   const gptReport = $('GPT Researcher').first().json.report;
   const verifications = $input.all().map(v => v.json);
   
   const verified = verifications.filter(v => v.verified && v.confidence >= 0.8);
   const unverified = verifications.filter(v => !v.verified || v.confidence < 0.8);
   
   return [{
     json: {
       originalReport: gptReport,
       verifiedClaims: verified.length,
       unverifiedClaims: unverified.length,
       confidenceAverage: verifications.reduce((sum, v) => sum + v.confidence, 0) / verifications.length,
       flaggedForReview: unverified,
       fullVerifications: verifications
     }
   }];
   ```

9. **Action Nodes** - Verifizierten Bericht speichern oder unverifizierte Behauptungen eskalieren

**Anwendungsfall**: Gesch√§ftsberichte mit hohem Risiko, beh√∂rdliche Einreichungen, Investoren-Kommunikation.

#### Beispiel 3: Kontinuierliche Faktenpr√ºfungs-Pipeline

Ver√∂ffentlichte Inhalte √ºberwachen und Genauigkeit kontinuierlich verifizieren.

**Workflow-Struktur:**
1. **Schedule Trigger**
   ```javascript
   Cron: 0 */6 * * *  // Alle 6 Stunden
   ```

2. **HTTP Request - Aktuelle Artikel abrufen**
   ```javascript
   // Von CMS, Website oder Content-API
   Methode: GET
   URL: https://your-cms.com/api/articles/recent
   ```

3. **Loop Over Articles**

4. **Code Node - Faktische Behauptungen extrahieren**
   ```javascript
   const article = $json.item;
   
   // Regex oder einfachen LLM-Aufruf verwenden, um Behauptungen zu extrahieren
   // Fokus auf: Statistiken, Daten, Zitate, Recherche-Referenzen
   const claims = extractFactualClaims(article.content);
   
   return claims.map(claim => ({
     json: {
       article_id: article.id,
       article_title: article.title,
       claim: claim,
       published_date: article.publishedAt
     }
   }));
   ```

5. **HTTP Request - Behauptungen mit Local Deep Research verifizieren**
   ```javascript
   Methode: POST
   URL: http://local-deep-research:2024/api/verify
   Body: {
     "statement": "{{ $json.claim }}",
     "published_date": "{{ $json.published_date }}",
     "iterations": 4
   }
   ```

6. **Wait + Poll + Ergebnisse**

7. **IF Node - Auf falsche Behauptungen pr√ºfen**
   ```javascript
   Bedingung: {{ $json.verified }} === false || {{ $json.confidence }} < 0.7
   ```

8. **Alarm-Pfad - Redaktionsteam benachrichtigen**
   ```javascript
   // Slack/E-Mail-Benachrichtigung
   Nachricht: |
     ‚ö†Ô∏è Potenzielle Ungenauigkeit erkannt
     
     Artikel: {{ $json.article_title }}
     Behauptung: {{ $json.claim }}
     Urteil: {{ $json.verdict }}
     Konfidenz: {{ $json.confidence }}
     
     Konsultierte Quellen: {{ $json.sources.length }}
     
     Bitte √ºberpr√ºfen und bei Bedarf aktualisieren.
   ```

**Anwendungsfall**: Content-Qualit√§tssicherung, redaktionelle Faktenpr√ºfung, Compliance-√úberwachung.

### Fehlerbehebung

**Problem 1: Recherche dauert zu lange (>20 Minuten)**

```bash
# Container-Status pr√ºfen
launchkit ps | grep local-deep-research

# Logs auf festgefahrene Prozesse ansehen
launchkit logs local-deep-research --tail 100 --follow
```

**L√∂sung:**
- `iterations` reduzieren (3 statt 5 versuchen)
- Anfrage vereinfachen: spezifischer sein
- Pr√ºfen, ob Such-Backend (SearXNG) reagiert:
  ```bash
  launchkit exec n8n curl http://searxng:8080/search?q=test
  ```

**Problem 2: Niedrige Konfidenz-Scores**

```bash
# Pr√ºfen, ob LLM-Provider funktioniert
launchkit logs local-deep-research | grep -i "llm\|error"
```

**L√∂sung:**
- Anfrage k√∂nnte zu mehrdeutig sein - spezifischer sein
- `iterations` auf 5-7 erh√∂hen f√ºr gr√ºndlichere Recherche
- Pr√ºfen, ob Thema aktiv umstritten ist (niedrige Konfidenz wird erwartet)
- LLM-Konfiguration verifizieren (OpenAI-Key oder Ollama-Verbindung)

**Problem 3: Suchmaschinen-Konnektivit√§tsprobleme**

```bash
# Such-Backend testen
launchkit exec local-deep-research curl http://searxng:8080/health

# Such-Logs pr√ºfen
launchkit logs searxng --tail 50
```

**L√∂sung:**
- Verifizieren, dass SearXNG oder anderes Such-Backend funktioniert
- Docker-Netzwerk-Konnektivit√§t pr√ºfen
- Such-Service neu starten:
  ```bash
  launchkit restart searxng local-deep-research
  ```

**Problem 4: Widerspr√ºchliche Informationen gefunden**

Dies ist tats√§chlich ein GUTES Zeichen - zeigt gr√ºndliche Recherche.

```bash
# Das Ergebnis wird enthalten:
{
  "contradictions_found": [
    {
      "claim": "...",
      "source1": "...",
      "source2": "...",
      "contradiction": "..."
    }
  ],
  "confidence_score": 0.65,  // Niedriger wegen Konflikten
  "warnings": ["Multiple contradictory sources found"]
}
```

**N√§chste Schritte:**
- Widerspr√ºche manuell √ºberpr√ºfen
- Iterationen erh√∂hen, um Konflikte zu l√∂sen
- Kontext hinzuf√ºgen, um Recherche zu zuverl√§ssigen Quellen zu leiten

**Problem 5: API-Timeout**

```bash
# Umgebungsvariablen pr√ºfen
launchkit exec local-deep-research printenv | grep -E "OPENAI|OLLAMA|SEARXNG"

# Auf Rate-Limiting pr√ºfen
launchkit logs local-deep-research | grep -i "rate\|limit\|quota"
```

**L√∂sung:**
- Ollama f√ºr lokale Inferenz verwenden (keine Rate-Limits):
  ```bash
  # In .env:
  LLM_PROVIDER=ollama
  OLLAMA_BASE_URL=http://ollama:11434
  ```
- Verz√∂gerungen zwischen mehreren Recherche-Anfragen in n8n hinzuf√ºgen
- Pr√ºfen, ob externe API-Kontingente √ºberschritten sind

### Best Practices

**Wann Local Deep Research nutzen:**

‚úÖ **Perfekt f√ºr:**
- Faktenpr√ºfung kritischer Gesch√§ftsentscheidungen
- Verifizierung von Statistiken und Finanzdaten
- Akademische Recherche mit hoher Genauigkeitsanforderung
- Beh√∂rdliche Compliance-Recherche
- Medizinische/wissenschaftliche Behauptungs-Verifizierung
- Rechtliche Recherche und Due Diligence

‚ùå **Nicht ideal f√ºr:**
- Schnelle √úberblicke (stattdessen GPT Researcher nutzen)
- Meinungsbasierte Fragen
- Kreative Content-Generierung
- Echtzeit-Daten (direkte APIs nutzen)
- Einfache Informations-Lookups

**Recherche-Strategie nach verf√ºgbarer Zeit:**

**Schnelle Recherche (2-5 Min):**
```
GPT Researcher (outline_report, 3 Iterationen)
‚Üí Nutzen f√ºr: √úberblicke, Brainstorming, erste Exploration
```

**Tiefenrecherche (10-20 Min):**
```
Local Deep Research (5 Iterationen, hohe Konfidenz)
‚Üí Nutzen f√ºr: Faktenpr√ºfung, detaillierte Analyse, Entscheidungsunterst√ºtzung
```

**Umfassende Recherche (30+ Min):**
```
GPT Researcher (Gliederung) ‚Üí Behauptungen extrahieren
‚Üí Local Deep Research (jede Behauptung verifizieren)
‚Üí Finalen Bericht synthetisieren
‚Üí Nutzen f√ºr: Kritische Entscheidungen, Publikationen, Compliance
```

**Optimierungstipps:**

- **Kontext ist der Schl√ºssel**: Immer vorherige Recherche als Kontext bereitstellen
- **Spezifische Anfragen**: "Was ist der ROI von X?" > "Erz√§hl mir √ºber X"
- **Schrittweise iterieren**: Mit 3 Iterationen beginnen, bei Bedarf erh√∂hen
- **Parallele Verarbeitung**: Mehrere Behauptungen gleichzeitig in n8n verifizieren
- **Ergebnisse cachen**: Verifizierte Fakten in Datenbank speichern, um erneute Recherche zu vermeiden

**Integrationsmuster:**

```javascript
// Muster 1: Schnell + Tief
GPT Researcher (√úberblick) ‚Üí Local Deep Research (Kernbehauptungen verifizieren)

// Muster 2: Multi-Quellen-Validierung
SearXNG (rohe Ergebnisse) ‚Üí Local Deep Research (synthetisieren + verifizieren)

// Muster 3: Kontinuierliche √úberwachung
Zeitplan ‚Üí Behauptungen sammeln ‚Üí Local Deep Research ‚Üí Alarm bei Falschheit

// Muster 4: Mensch in der Schleife
Local Deep Research ‚Üí Falls Konfidenz < 0.8 ‚Üí Menschliche √úberpr√ºfung
```

### Ressourcen

- **Offizielle Dokumentation**: https://github.com/langchain-ai/local-deep-researcher
- **GitHub Repository**: https://github.com/langchain-ai/local-deep-researcher
- **LangChain Docs**: https://python.langchain.com/docs/
- **Interne API**: `http://local-deep-research:2024`
- **WebSocket-Updates**: `ws://local-deep-research:2024/ws/{task_id}`

**Verwandte Services:**
- Mit **GPT Researcher** f√ºr Schnell + Tief-Strategie kombinieren
- **SearXNG** als Such-Backend nutzen
- Ergebnisse in **PostgreSQL** oder **Supabase** speichern
- Mit **Ollama** f√ºr lokale LLM-Inferenz verarbeiten
- Mit **Perplexica** f√ºr alternative Perspektiven vergleichen
