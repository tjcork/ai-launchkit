# üé® ComfyUI - Bildgenerierung

### Was ist ComfyUI?

ComfyUI ist eine leistungsstarke node-basierte Oberfl√§che f√ºr Stable Diffusion und andere KI-Bildgenerierungsmodelle. Im Gegensatz zu einfachen Prompt-zu-Bild-Tools bietet ComfyUI ein visuelles Workflow-System, bei dem du Nodes verbindest, um komplexe Bildgenerierungs-Pipelines zu erstellen. Es ist hochgradig anpassbar, unterst√ºtzt mehrere Modelle und ist perfekt sowohl f√ºr Anf√§nger als auch f√ºr fortgeschrittene Benutzer, die volle Kontrolle √ºber ihren KI-Bildgenerierungsprozess w√ºnschen.

### Funktionen

- **Node-basierter Workflow** - Visuelle Programmierung f√ºr Bildgenerierungs-Pipelines
- **Mehrere Modelle unterst√ºtzt** - FLUX, SDXL, SD 1.5, ControlNet, LoRA und mehr
- **Benutzerdefinierte Workflows** - Vollst√§ndige Generierungs-Pipelines speichern und teilen
- **Erweiterte Kontrolle** - ControlNet, IP-Adapter, Inpainting, Outpainting
- **Batch-Verarbeitung** - Mehrere Varianten effizient generieren
- **API-Unterst√ºtzung** - Programmatischer Zugriff f√ºr n8n-Integration
- **Modell-Manager** - Einfache Modellinstallation und -verwaltung
- **Community-Workflows** - Tausende vorgefertigte Workflows verf√ºgbar
- **Benutzerdefinierte Nodes** - Erweiterbar mit von der Community erstellten Node-Paketen
- **Hohe Leistung** - F√ºr GPU-Beschleunigung optimiert

### Ersteinrichtung

**Erster Login bei ComfyUI:**

1. Navigiere zu `https://comfyui.deinedomain.com`
2. Die Oberfl√§che l√§dt sofort - kein Login erforderlich
3. Du siehst den Standard-Workflow (Text-zu-Bild)
4. **Wichtig:** Keine Modelle sind vorinstalliert - du musst sie zuerst herunterladen

**ComfyUI ist einsatzbereit, ben√∂tigt aber Modelle!**

### Essentielle Modelle herunterladen

ComfyUI ben√∂tigt KI-Modelle, um Bilder zu generieren. So geht's los:

**Option 1: Download √ºber Web-UI (Am einfachsten)**

1. Klicke auf **Manager**-Button (unten rechts)
2. W√§hle **Install Models**
3. W√§hle Modellkategorie:
   - **Checkpoints:** Basismodelle (FLUX, SDXL, SD 1.5)
   - **LoRA:** Stil-Modifikatoren
   - **ControlNet:** Posen-/Kantenkontrolle
   - **VAE:** Bild-Encoder/Decoder
4. Klicke auf **Install** neben dem gew√ºnschten Modell
5. Warte auf Abschluss des Downloads

**Option 2: Manueller Download**

```bash
# Auf ComfyUI-Modellverzeichnis zugreifen
cd /var/lib/docker/volumes/${PROJECT_NAME:-localai}_comfyui_data/_data/models

# FLUX.1-schnell herunterladen (schnell, empfohlen f√ºr Anf√§nger)
cd checkpoints
wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors

# SDXL herunterladen (vielseitig, gute Qualit√§t)
wget https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors

# VAE herunterladen (erforderlich f√ºr SDXL)
cd ../vae
wget https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors

# ComfyUI neu starten, um neue Modelle zu erkennen
docker compose restart comfyui
```

**Empfohlene Modelle f√ºr Anf√§nger:**

| Modell | Gr√∂√üe | Am besten f√ºr | Download-Priorit√§t |
|--------|-------|---------------|-------------------|
| **FLUX.1-schnell** | 23GB | Schnelle Generierung, gro√üartige Qualit√§t | ‚≠ê Essentiell |
| **SDXL Base 1.0** | 6.5GB | Vielseitig, fotorealistisch | ‚≠ê Essentiell |
| **SD 1.5** | 4GB | Schnell, breite LoRA-Unterst√ºtzung | ‚≠ê‚≠ê Empfohlen |
| **SDXL Turbo** | 6.5GB | Ultra-schnell, 1-Schritt-Generierung | ‚≠ê‚≠ê Empfohlen |

**Modell-Speicherorte:**

```
checkpoints/     - Basismodelle (FLUX, SDXL, SD 1.5)
loras/          - Stil-Modifikatoren
controlnet/     - Posen- und Kantenkontroll-Modelle
vae/            - Bild-Encoder/Decoder
upscale_models/ - KI-Upscaler
embeddings/     - Textual Inversion Embeddings
```

### Grundlegende Bildgenerierung

**Einfaches Text-zu-Bild:**

1. Lade den Standard-Workflow (oder aktualisiere die Seite)
2. Finde den **Load Checkpoint**-Node
3. W√§hle dein heruntergeladenes Modell aus dem Dropdown
4. Finde den **CLIP Text Encode (Prompt)**-Node
5. Gib deinen positiven Prompt ein: `"eine wundersch√∂ne Landschaft mit Bergen und See, goldene Stunde, 8k, hochdetailliert"`
6. Gib negativen Prompt ein: `"verschwommen, niedrige Qualit√§t, verzerrt"`
7. Klicke auf **Queue Prompt** (rechte Seitenleiste)
8. Warte auf Generierung (10-60 Sekunden je nach Modell)
9. Bild erscheint im **Save Image**-Node

**Workflow-Steuerung:**

- **Queue Prompt:** Generierung starten
- **Clear:** Alle in der Warteschlange befindlichen Prompts entfernen
- **Manager:** Modelle und benutzerdefinierte Nodes installieren
- **Load:** Gespeicherte Workflows importieren
- **Save:** Aktuellen Workflow exportieren

### n8n-Integration einrichten

**ComfyUI API-Konfiguration:**

ComfyUI bietet eine REST-API f√ºr programmatische Bildgenerierung von n8n aus.

**Interne URL f√ºr n8n:** `http://comfyui:8188`

**API-Endpunkte:**
- `/prompt` - Generierungs-Job in Warteschlange einreihen
- `/history` - Generierungsverlauf abrufen
- `/queue` - Warteschlangen-Status pr√ºfen
- `/view` - Generierte Bilder abrufen

### Beispiel-Workflows

#### Beispiel 1: KI Social-Media-Content-Generator

Automatisch Bilder f√ºr Social-Media-Posts generieren:

```javascript
// Gebrandete Social-Media-Bilder aus Text-Prompts generieren

// 1. Schedule Trigger - T√§glich um 9 Uhr
// Oder: Webhook f√ºr On-Demand-Generierung

// 2. Code Node - Prompts vorbereiten
const topics = [
  "moderner minimalistischer Arbeitsplatz",
  "gesunde Fr√ºhst√ºckssch√ºssel",
  "Sonnenuntergang am Strand",
  "gem√ºtliches Caf√©"
];

const selectedTopic = topics[Math.floor(Math.random() * topics.length)];

const comfyWorkflow = {
  "3": {
    "inputs": {
      "seed": Math.floor(Math.random() * 1000000),
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": ["4", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["5", 0]
    },
    "class_type": "KSampler"
  },
  "4": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "6": {
    "inputs": {
      "text": `${selectedTopic}, professionelle Fotografie, hohe Qualit√§t, 8k, trending auf artstation`,
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "verschwommen, niedrige Qualit√§t, verzerrt, h√§sslich, schlechte Anatomie",
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": ["3", 0],
      "vae": ["4", 2]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": "social_media",
      "images": ["8", 0]
    },
    "class_type": "SaveImage"
  }
};

return {
  json: {
    prompt: comfyWorkflow,
    topic: selectedTopic
  }
};

// 3. HTTP Request Node - An ComfyUI senden
Methode: POST
URL: http://comfyui:8188/prompt
Header:
  Content-Type: application/json
Body (JSON):
{
  "prompt": {{$json.prompt}},
  "client_id": "n8n-workflow"
}

// 4. Wait Node - Auf Generierung warten
Betrag: 60
Unit: seconds

// 5. HTTP Request Node - Generiertes Bild abrufen
Methode: GET
URL: http://comfyui:8188/history/{{$('Queue Generation').json.prompt_id}}
Response Format: JSON

// 6. Code Node - Bilddaten extrahieren
const history = $input.first().json;
const promptId = Object.keys(history)[0];
const outputs = history[promptId].outputs;

// Bild-Output finden
let imageInfo;
for (const nodeId in outputs) {
  if (outputs[nodeId].images) {
    imageInfo = outputs[nodeId].images[0];
    break;
  }
}

return {
  json: {
    filename: imageInfo.filename,
    subfolder: imageInfo.subfolder,
    type: imageInfo.type
  }
};

// 7. HTTP Request Node - Bild herunterladen
Methode: GET
URL: http://comfyui:8188/view?filename={{$json.filename}}&subfolder={{$json.subfolder}}&type={{$json.type}}
Response Format: File
Output Property Name: data

// 8. Move Binary - Datei umbenennen
Mode: Move to new property
From Property: data
To Property: image
New File Name: social_{{$now.format('YYYY-MM-DD')}}.png

// 9. Google Drive Node - Zu Drive hochladen
Operation: Upload
File: {{$binary.image}}
Folder: Social Media Content
Name: {{$('Code - Extract').json.filename}}

// 10. Slack Node - Mit Team teilen
Kanal: #marketing
Nachricht: |
  üé® Neues Social-Media-Bild generiert!
  
  Thema: {{$('Prepare Prompts').json.topic}}
  
  üìÅ Verf√ºgbar in Google Drive: Social Media Content
  
Anh√§nge: {{$binary.image}}
```

#### Beispiel 2: Produktfotografie-Automatisierung

Konsistente Produktbilder f√ºr E-Commerce generieren:

```javascript
// Professionelle Produktfotos mit konsistentem Stil erstellen

// 1. Webhook Trigger - Produktdetails empfangen
// Payload: { "product_name": "Moderner Stuhl", "color": "blau", "style": "minimalistisch" }

// 2. Code Node - Detaillierten Prompt erstellen
const product = $json.product_name;
const color = $json.color;
const style = $json.style || "modern";

const positivePrompt = `professionelle Produktfotografie von ${product}, ${color} Farbe, ${style} Stil, wei√üer Hintergrund, Studio-Beleuchtung, hohe Aufl√∂sung, scharfer Fokus, kommerzielle Fotografie, E-Commerce-Foto`;

const negativePrompt = "verschwommen, Schatten, unordentlicher Hintergrund, verzerrt, niedrige Qualit√§t, Wasserzeichen";

// Workflow-Template laden
const workflow = {
  "4": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "6": {
    "inputs": {
      "text": positivePrompt,
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": negativePrompt,
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "3": {
    "inputs": {
      "seed": Math.floor(Math.random() * 999999),
      "steps": 25,
      "cfg": 7.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["4", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["5", 0]
    },
    "class_type": "KSampler"
  },
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 4  // 4 Varianten generieren
    },
    "class_type": "EmptyLatentImage"
  },
  "8": {
    "inputs": {
      "samples": ["3", 0],
      "vae": ["4", 2]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": `product_${product.replace(/\s+/g, '_')}`,
      "images": ["8", 0]
    },
    "class_type": "SaveImage"
  }
};

return {
  json: {
    workflow,
    product,
    positivePrompt
  }
};

// 3. HTTP Request - Generierung in Warteschlange einreihen
Methode: POST
URL: http://comfyui:8188/prompt
Body: { "prompt": {{$json.workflow}} }

// 4. Wait - Generierungszeit erm√∂glichen
Betrag: 90
Unit: seconds

// 5. HTTP Request - Ergebnisse abrufen
Methode: GET
URL: http://comfyui:8188/history/{{$('Queue Generation').json.prompt_id}}

// 6. Code Node - Alle generierten Bilder verarbeiten
const history = $input.first().json;
const promptId = Object.keys(history)[0];
const outputs = history[promptId].outputs;

const images = [];
for (const nodeId in outputs) {
  if (outputs[nodeId].images) {
    outputs[nodeId].images.forEach(img => {
      images.push({
        filename: img.filename,
        subfolder: img.subfolder,
        type: img.type
      });
    });
  }
}

return images.map(img => ({ json: img }));

// 7. Loop Over Items - Jede Variante verarbeiten

// 8. HTTP Request - Bild herunterladen
Methode: GET
URL: http://comfyui:8188/view?filename={{$json.filename}}&subfolder={{$json.subfolder}}&type={{$json.type}}
Response Format: File

// 9. Supabase Node - In Datenbank speichern
Operation: Einf√ºgen
Table: product_images
Daten:
  product_id: {{$('Webhook').json.product_id}}
  image_url: Generated URL
  style: {{$('Webhook').json.style}}
  color: {{$('Webhook').json.color}}
  created_at: {{$now.toISO()}}

// 10. S3/Cloudflare R2 - Zu CDN hochladen (optional)
// F√ºr Produktions-Serving

// 11. Email Node - Produktteam benachrichtigen (nach Loop-Ende)
To: product-team@company.com
Subject: Produktbilder generiert: {{$('Build Prompt').json.product}}
Body: |
  ‚úÖ Produktfotografie abgeschlossen!
  
  Produkt: {{$('Build Prompt').json.product}}
  Varianten: 4 Bilder generiert
  Stil: {{$('Webhook').json.style}}
  
  Bilder verf√ºgbar in Produktdatenbank.
  
  Verwendeter Prompt: {{$('Build Prompt').json.positivePrompt}}
```

#### Beispiel 3: KI-Kunst-Pipeline mit Stil-Transfer

Konsistente gebrandete Kunstwerke erstellen:

```javascript
// Kunstwerke generieren, die den Markenrichtlinien entsprechen

// 1. Schedule Trigger - W√∂chentliche Content-Generierung

// 2. Read Binary Files - Stil-Referenzbild laden
File Pfad: /data/shared/brand_style_reference.png

// 3. Code Node - Workflow mit ControlNet vorbereiten
const workflow = {
  // Modelle laden
  "1": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  
  // ControlNet f√ºr Stil-Transfer laden
  "2": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_canny.pth"
    },
    "class_type": "ControlNetLoader"
  },
  
  // Prompts
  "6": {
    "inputs": {
      "text": "abstrakte digitale Kunst, lebendige Farben, geometrische Formen, modernes Design, professionelle Illustration",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "h√§sslich, verschwommen, niedrige Qualit√§t, verzerrt",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  
  // Generierungs-Einstellungen
  "3": {
    "inputs": {
      "seed": Math.floor(Math.random() * 999999),
      "steps": 30,
      "cfg": 8.5,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 0.85,
      "model": ["1", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["5", 0]
    },
    "class_type": "KSampler"
  },
  
  // Latent Image
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  
  // Dekodieren und speichern
  "8": {
    "inputs": {
      "samples": ["3", 0],
      "vae": ["1", 2]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": "branded_art",
      "images": ["8", 0]
    },
    "class_type": "SaveImage"
  }
};

return { json: { workflow } };

// 4. HTTP Request - Generieren
Methode: POST
URL: http://comfyui:8188/prompt
Body: { "prompt": {{$json.workflow}} }

// 5. Wait - Generierungszeit
Betrag: 120 seconds

// 6. HTTP Request - Bild abrufen
// ... (√§hnlich wie in vorherigen Beispielen)

// 7. OpenAI Vision Node - Marken-Compliance pr√ºfen
Modell: gpt-4o
System: "Du bist ein Marken-Compliance-Pr√ºfer. Analysiere, ob das Bild den Markenrichtlinien entspricht."
User: "Entspricht dieses Bild unserem Markenstil? Sei spezifisch."
Image: {{$binary.image}}

// 8. IF Node - KI-Genehmigung pr√ºfen
Bedingung: {{$json.message.content}} enth√§lt "entspricht"

// Zweig: Genehmigt
// 9a. In Produktionsordner verschieben
// 10a. In sozialen Medien posten

// Zweig: Abgelehnt
// 9b. Zur manuellen √úberpr√ºfung einreihen
// 10b. Design-Team benachrichtigen
```

### Benutzerdefinierte Workflows

**Deinen Workflow speichern:**

1. Erstelle deinen Workflow in ComfyUI
2. Klicke auf **Save**-Button
3. Gib Dateinamen ein: `mein_workflow.json`
4. Workflow wird in `/output/workflows/` gespeichert

**Gespeicherten Workflow laden:**

1. Klicke auf **Load**-Button
2. W√§hle deinen Workflow aus der Liste
3. Workflow l√§dt automatisch

**Workflows teilen:**

- JSON aus ComfyUI exportieren
- √úber GitHub, Civitai oder ComfyUI-Foren teilen
- Workflows anderer mit **Load** importieren

### Fehlerbehebung

**Problem 1: "No model loaded"-Fehler**

```bash
# Installierte Modelle pr√ºfen
docker exec comfyui ls -la /app/models/checkpoints/

# Pr√ºfen, ob Modell im .safetensors-Format ist
# Modelle m√ºssen im korrekten Unterverzeichnis sein

# Fehlendes Modell herunterladen
docker exec comfyui wget -P /app/models/checkpoints/ \
  https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors

# ComfyUI neu starten
docker compose restart comfyui
```

**L√∂sung:**
- Sicherstellen, dass Modelle im Verzeichnis `/models/checkpoints/` sind
- `.safetensors`-Format verwenden (nicht `.ckpt`)
- ComfyUI-Seite nach Hinzuf√ºgen von Modellen aktualisieren
- Pr√ºfen, dass Modell-Dateiname im Workflow genau √ºbereinstimmt

**Problem 2: Out of Memory / CUDA-Fehler**

```bash
# GPU-Speicher-Nutzung pr√ºfen
docker exec comfyui nvidia-smi

# Batch-Gr√∂√üe im Workflow reduzieren
# Von batch_size: 4 zu batch_size: 1 √§ndern

# Kleinere Modelle verwenden
# SDXL Turbo (6GB) statt FLUX (23GB)

# Low-VRAM-Modus in ComfyUI-Einstellungen aktivieren
# Einstellungen ‚Üí Execution ‚Üí CPU-Fallback aktivieren
```

**L√∂sung:**
- Niedrigere Aufl√∂sung verwenden (512x512 oder 768x768)
- Batch-Gr√∂√üe auf 1 reduzieren
- Quantisierte Modelle verwenden (fp16 statt fp32)
- Andere GPU-Anwendungen schlie√üen
- GPU upgraden oder Cloud-GPU verwenden

**Problem 3: Langsame Generierungszeiten**

```bash
# Pr√ºfen, ob GPU verwendet wird
docker exec comfyui nvidia-smi

# CUDA-Funktionalit√§t verifizieren
docker exec comfyui python -c "import torch; print(torch.cuda.is_available())"

# xFormers f√ºr schnellere Generierung aktivieren
# Zu docker-compose.yml hinzuf√ºgen:
#   environment:
#     - COMMANDLINE_ARGS=--use-xformers
```

**L√∂sung:**
- SDXL Turbo oder LCM-Modelle f√ºr schnellere Generierung verwenden
- Schrittzahl reduzieren (15-20 Schritte statt 30-50)
- Effiziente Sampler verwenden: `euler_a`, `dpm++ 2m`
- TensorRT-Optimierung aktivieren
- Niedrigeren CFG-Scale verwenden (6-8 statt 10-15)

**Problem 4: API-Verbindungsfehler von n8n**

```bash
# API-Konnektivit√§t testen
curl http://comfyui:8188/system_stats

# ComfyUI-Logs pr√ºfen
docker logs comfyui --tail 50

# Pr√ºfen, ob ComfyUI l√§uft
docker ps | grep comfyui

# Bei Bedarf neu starten
docker compose restart comfyui
```

**L√∂sung:**
- Interne URL verwenden: `http://comfyui:8188` von n8n aus
- Sicherstellen, dass ComfyUI-Container l√§uft
- Pr√ºfen, dass Prompt-JSON g√ºltig ist
- HTTP-Request-Timeout auf 120 Sekunden erh√∂hen
- Warteschlange √ºberwachen: `http://comfyui:8188/queue`

### Ressourcen

- **Offizielles GitHub:** https://github.com/comfyanonymous/ComfyUI
- **Dokumentation:** https://docs.comfy.org/
- **Modell-Downloads:** https://civitai.com/ (gr√∂√üte Modellbibliothek)
- **Community-Workflows:** https://comfyworkflows.com/
- **Benutzerdefinierte Nodes:** https://github.com/ltdrdata/ComfyUI-Manager
- **API-Dokumentation:** https://github.com/comfyanonymous/ComfyUI/wiki/API
- **Discord-Community:** https://discord.gg/comfyui
- **Video-Tutorials:** https://www.youtube.com/c/OlivioSarikas

### Best Practices

**Modellverwaltung:**
1. **Klein anfangen** - SDXL zuerst herunterladen, andere nach Bedarf hinzuf√ºgen
2. **Modelle organisieren** - Unterordner f√ºr verschiedene Modelltypen verwenden
3. **Regelm√§√üige Bereinigung** - Ungenutzte Modelle entfernen, um Speicherplatz zu sparen
4. **Modelle testen** - Neue Modelle immer zuerst mit einfachen Prompts testen
5. **Workflows sichern** - Wichtige Workflows regelm√§√üig exportieren

**Prompt Engineering:**
- **Spezifisch sein** - "rotes Sportauto" vs "vintage roter Ferrari 250 GTO"
- **Qualit√§ts-Tags verwenden** - "8k, hochdetailliert, professionelle Fotografie"
- **Negative Prompts** - Immer einschlie√üen: "verschwommen, niedrige Qualit√§t, verzerrt"
- **Stil-Modifikatoren** - "im Stil von [K√ºnstler/Bewegung]"
- **Komposition** - Spezifizieren: "Nahaufnahme", "Weitwinkel", "Vogelperspektive"

**Performance-Optimierung:**
1. **Aufl√∂sung** - Bei 512x512 starten, sp√§ter hochskalieren falls n√∂tig
2. **Schritte** - 20-30 Schritte sind normalerweise ausreichend
3. **CFG Scale** - 7-8 f√ºr die meisten F√§lle, h√∂her f√ºr mehr Prompt-Treue
4. **Sampler** - `euler_a` oder `dpmpp_2m` f√ºr Geschwindigkeit
5. **Batch-Generierung** - Mehrere Varianten in einem Durchlauf generieren

**n8n-Integrations-Tipps:**
1. **Asynchrone Verarbeitung** - Immer Wait-Node nach Einreihung einschlie√üen
2. **Fehlerbehandlung** - Try/Catch um ComfyUI-Aufrufe hinzuf√ºgen
3. **Rate Limiting** - Nicht mehr als 3-5 Prompts gleichzeitig einreihen
4. **Bildspeicherung** - Sofort nach Generierung in S3/Drive speichern
5. **Monitoring** - Generierungszeiten und Erfolgsraten protokollieren

**Sicherheit:**
- ComfyUI hat standardm√§√üig keine Authentifizierung
- Caddy Reverse Proxy f√ºr HTTPS und Basic Auth verwenden
- ComfyUI nicht direkt ins Internet exponieren
- API-Zugriff nur √ºber n8n (internes Netzwerk)
- Regelm√§√üige Backups von Modellen und Workflows
