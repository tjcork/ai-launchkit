# üìù Scriberr - Audio-Transkription mit Sprecher-Diarisierung

### Was ist Scriberr?

Scriberr ist ein fortschrittlicher KI-gest√ºtzter Audio-Transkriptionsdienst, der auf WhisperX basiert und hochpr√§zise Transkription mit Sprecher-Diarisierung (Identifizierung wer was gesagt hat) bietet. Perfekt f√ºr Meetings, Interviews, Podcasts und Anrufaufzeichnungen - Scriberr geht √ºber einfache Transkription hinaus, indem es automatisch verschiedene Sprecher identifiziert und kennzeichnet, was es ideal f√ºr Multi-Sprecher-Inhaltsanalyse macht.

### Funktionen

- **WhisperX-basierte Transkription** - Hohe Genauigkeit mit pr√§ziser Zeitstempel-Ausrichtung
- **Sprecher-Diarisierung** - Identifiziert und kennzeichnet automatisch verschiedene Sprecher (Sprecher 1, Sprecher 2, etc.)
- **KI-Zusammenfassungen** - Generiere Meeting-Zusammenfassungen mit OpenAI- oder Anthropic-Modellen
- **YouTube-Unterst√ºtzung** - Transkribiere direkt von YouTube-URLs ohne Download
- **REST-API** - Volle Automatisierungsunterst√ºtzung f√ºr n8n und andere Tools
- **Mehrere Modelloptionen** - W√§hle zwischen tiny bis large Modellen basierend auf Genauigkeitsbedarf
- **Mehrsprachige Unterst√ºtzung** - Unterst√ºtzt 99 Sprachen mit automatischer Erkennung

### Erste Einrichtung

**Erster Login bei Scriberr:**

1. Navigiere zu `https://scriberr.deinedomain.com`
2. Keine Authentifizierung standardm√§√üig erforderlich (nur internes Netzwerk)
3. Lade eine Test-Audiodatei hoch oder f√ºge eine YouTube-URL ein
4. Konfiguriere Sprechererkennungseinstellungen:
   - **Min Sprecher**: Minimale Anzahl erwarteter Sprecher (Standard: 2)
   - **Max Sprecher**: Maximale Anzahl zu identifizierender Sprecher (Standard: 4)
5. Klicke auf "Transkribieren" und warte auf Verarbeitung
6. Erste Transkription l√§dt das Modell herunter (2-5 Minuten Ersteinrichtung)
7. Betrachte Ergebnisse mit Sprecher-Labels und Zeitstempeln

**Modellauswahl:**
- **tiny** (~1GB RAM): Schnelle Verarbeitung, Entwurfsqualit√§t
- **base** (~1,5GB RAM): Gute Balance, empfohlener Standard
- **small** (~3GB RAM): Bessere Genauigkeit f√ºr Akzente
- **medium** (~5GB RAM): Professionelle Transkription
- **large** (~10GB RAM): Maximale Genauigkeit, langsamere Verarbeitung

### n8n-Integration einrichten

**Zugriff auf Scriberr-API von n8n:**

Scriberr bietet eine REST-API f√ºr vollst√§ndige Automatisierung. Verwende n8ns HTTP-Request-Node, um mit allen Funktionen zu interagieren.

**Interne URL:** `http://scriberr:8080`

**Verf√ºgbare Endpunkte:**
- `POST /api/upload` - Audiodatei hochladen und transkribieren
- `GET /api/transcripts/{id}` - Transkript nach ID abrufen
- `POST /api/youtube` - Von YouTube-URL transkribieren
- `POST /api/summary` - KI-Zusammenfassung des Transkripts generieren
- `GET /api/models` - Verf√ºgbare Whisper-Modelle auflisten

### Beispiel-Workflows

#### Beispiel 1: Meeting-Aufzeichnung zu Transkript mit Sprechern

```javascript
// Kompletter Workflow: Hochladen ‚Üí Transkribieren ‚Üí Sprecher identifizieren ‚Üí Ergebnisse per E-Mail

// 1. HTTP-Request-Node - Audiodatei hochladen
Methode: POST
URL: http://scriberr:8080/api/upload
Send Body: Form Data Multipart
Body Parameter:
  - Datei: {{ $binary.data }}  // n8n Binary File
  - speaker_detection: true
  - min_speakers: 2
  - max_speakers: 4
  - model: base  // oder: tiny, small, medium, large

// Antwort enth√§lt transcript_id f√ºr n√§chste Schritte

// 2. Wait-Node - Verarbeitungszeit
Time: 30 seconds
// Anpassen basierend auf Audio-L√§nge (1:1 Verh√§ltnis typisch)

// 3. HTTP-Request-Node - Transkript-Ergebnisse abrufen
Methode: GET
URL: http://scriberr:8080/api/transcripts/{{$json.transcript_id}}

// Antwortformat:
{
  "transcript_id": "abc123",
  "status": "completed",
  "text": "Vollst√§ndiger Transkript-Text...",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "Hallo zusammen, willkommen zum Meeting.",
      "speaker": "SPEAKER_00"
    },
    {
      "start": 3.5,
      "end": 7.2,
      "text": "Danke f√ºr die Einladung.",
      "speaker": "SPEAKER_01"
    }
  ],
  "speakers": {
    "SPEAKER_00": "Sprecher 1",
    "SPEAKER_01": "Sprecher 2"
  }
}

// 4. Code-Node - Transkript mit Sprecher-Labels formatieren
const segments = $input.item.json.segments;
const speakers = $input.item.json.speakers;

const formatted = segments.map(seg => {
  const speakerLabel = speakers[seg.speaker] || seg.speaker;
  const timestamp = new Date(seg.start * 1000).toISOString().substr(11, 8);
  return `[${timestamp}] ${speakerLabel}: ${seg.text}`;
}).join('\n\n');

return {
  formatted_transcript: formatted,
  full_text: $input.item.json.text
};

// 5. E-Mail-Node - Transkript an Teilnehmer senden
To: meeting@company.com
Subject: Meeting-Transkript - {{ $now.format('YYYY-MM-DD') }}
Body: |
  Meeting-Transkript (mit Sprecheridentifikation):
  
  {{ $json.formatted_transcript }}
  
  ---
  Vollst√§ndiges Transkript im Anhang.
```

#### Beispiel 2: YouTube-Video zu Meeting-Protokoll

```javascript
// YouTube-Video transkribieren und KI-Zusammenfassung generieren

// 1. Webhook-Trigger - YouTube-URL empfangen
// Input: { "youtube_url": "https://youtube.com/watch?v=..." }

// 2. HTTP-Request-Node - YouTube-Video transkribieren
Methode: POST
URL: http://scriberr:8080/api/youtube
Send Body: JSON
{
  "url": "{{ $json.youtube_url }}",
  "speaker_detection": true,
  "min_speakers": 1,
  "max_speakers": 5,
  "model": "small"  // Besser f√ºr Online-Videos
}

// Antwort: { "transcript_id": "xyz789", "status": "processing" }

// 3. Wait-Node - YouTube-Verarbeitung
Time: 2 minutes
// YouTube-Downloads dauern l√§nger

// 4. HTTP-Request-Node - Transkript-Status pr√ºfen
Methode: GET
URL: http://scriberr:8080/api/transcripts/{{$json.transcript_id}}

// 5. HTTP-Request-Node - KI-Zusammenfassung generieren
Methode: POST
URL: http://scriberr:8080/api/summary
Send Body: JSON
{
  "transcript_id": "{{$json.transcript_id}}",
  "prompt": "Erstelle detailliertes Meeting-Protokoll mit:\n- Hauptdiskussionspunkte\n- Wichtige Entscheidungen\n- Aktionspunkte mit zugewiesenen Verantwortlichen\n- Follow-up-Punkte",
  "model": "gpt-4o-mini"  // oder: gpt-4, claude-3-5-sonnet
}

// Antwort:
{
  "summary": "# Meeting-Protokoll\n\n## Hauptpunkte...",
  "action_items": ["Aufgabe 1", "Aufgabe 2"]
}

// 6. Google Docs-Node - Dokument erstellen
Title: Meeting-Protokoll - {{ $now.format('YYYY-MM-DD') }}
Inhalt: |
  # Video-Meeting-Protokoll
  
  **Video:** {{ $json.youtube_url }}
  **Datum:** {{ $now.format('YYYY-MM-DD HH:mm') }}
  
  ## KI-Generierte Zusammenfassung
  {{ $json.summary }}
  
  ## Vollst√§ndiges Transkript mit Sprechern
  {{ $json.transcript_text }}
  
  ## Aktionspunkte
  {{ $json.action_items.map(item => `- [ ] ${item}`).join('\n') }}

// 7. Slack-Node - Team benachrichtigen
Kanal: #meetings
Nachricht: |
  üìù Neues Meeting-Protokoll verf√ºgbar:
  {{ $json.document_url }}
  
  Wichtige Aktionspunkte:
  {{ $json.action_items[0] }}
  {{ $json.action_items[1] }}
```

#### Beispiel 3: Podcast-Verarbeitung mit Sprecher-Identifikation

```javascript
// Automatisierter Podcast-Transkriptions-Workflow

// 1. Google Drive-Trigger - Neue Datei im /Podcasts Ordner
// √úberwacht neue Audio-Uploads

// 2. Google Drive-Node - Audiodatei herunterladen
File ID: {{ $json.id }}
Output: Binary

// 3. HTTP-Request-Node - Zu Scriberr hochladen
Methode: POST
URL: http://scriberr:8080/api/upload
Body: Form Data Multipart
  - Datei: {{ $binary.data }}
  - speaker_detection: true
  - min_speakers: 2  // Host + Gast
  - max_speakers: 3  // Falls mehrere G√§ste
  - model: medium  // Besser f√ºr Produktionsqualit√§t

// 4. Wait-Node - Verarbeitung
Time: {{ Math.ceil($json.duration / 60) }} minutes
// Verarbeitungszeit ‚âà Audio-L√§nge

// 5. Loop-Node - Abfrage auf Fertigstellung
// Alle 30 Sekunden pr√ºfen bis status = "completed"

// 6. HTTP-Request-Node - Ergebnisse abrufen
Methode: GET
URL: http://scriberr:8080/api/transcripts/{{$json.transcript_id}}

// 7. Code-Node - Podcast-Show-Notes erstellen
const segments = $input.item.json.segments;
const speakers = $input.item.json.speakers;

// Nach Sprecher gruppieren
const speakerSegments = {};
segments.forEach(seg => {
  if (!speakerSegments[seg.speaker]) {
    speakerSegments[seg.speaker] = [];
  }
  speakerSegments[seg.speaker].push(seg);
});

// Zeitstempel f√ºr bemerkenswerte Momente generieren
const timestamps = [];
segments.forEach((seg, i) => {
  const words = seg.text.split(' ');
  if (words.some(w => ['frage', 'wichtig', 'schl√ºssel', 'zusammenfassung'].includes(w.toLowerCase()))) {
    timestamps.push({
      time: Math.floor(seg.start),
      text: seg.text.substring(0, 100)
    });
  }
});

return {
  full_transcript: $input.item.json.text,
  speaker_count: Object.keys(speakerSegments).length,
  timestamps: timestamps.slice(0, 10),  // Top 10 Momente
  duration: segments[segments.length - 1].end
};

// 8. WordPress-Node - Show-Notes ver√∂ffentlichen
Title: {{ $json.podcast_title }}
Inhalt: |
  ## Podcast-Episode-Notizen
  
  **Dauer:** {{ Math.floor($json.duration / 60) }} Minuten
  **Sprecher:** {{ $json.speaker_count }}
  
  ### Wichtige Momente
  {{ $json.timestamps.map(t => `[${Math.floor(t.time / 60)}:${t.time % 60}] ${t.text}`).join('\n') }}
  
  ### Vollst√§ndiges Transkript
  {{ $json.full_transcript }}
  
  ---
  *Transkript automatisch generiert mit Scriberr*

// 9. Social-Media-Nodes - Episode bewerben
// Twitter, LinkedIn, etc. mit Schl√ºsselzitaten
```

#### Beispiel 4: Kundensupport-Anruf-Analyse

```javascript
// Support-Anrufe auf Qualit√§t und Erkenntnisse analysieren

// 1. FTP-Trigger - Neue Anrufaufzeichnungen hochgeladen
// Oder Webhook vom Telefonsystem

// 2. HTTP-Request - Anruf transkribieren
Methode: POST
URL: http://scriberr:8080/api/upload
Body:
  - Datei: {{ $binary.data }}
  - speaker_detection: true
  - min_speakers: 2  // Agent + Kunde
  - max_speakers: 2

// 3. Wait + Transkript abrufen (siehe Beispiel 1)

// 4. Code-Node - Anrufqualit√§t analysieren
const segments = $input.item.json.segments;

// Agent vs. Kunde identifizieren
const agentSpeaker = segments[0].speaker;  // Erster Sprecher = Agent
const customerSpeaker = segments.find(s => s.speaker !== agentSpeaker)?.speaker;

// Metriken berechnen
const agentWords = segments
  .filter(s => s.speaker === agentSpeaker)
  .reduce((sum, s) => sum + s.text.split(' ').length, 0);
  
const customerWords = segments
  .filter(s => s.speaker === customerSpeaker)
  .reduce((sum, s) => sum + s.text.split(' ').length, 0);

const talkRatio = agentWords / customerWords;
const callDuration = segments[segments.length - 1].end;
const avgPause = segments.reduce((sum, s, i, arr) => {
  if (i === 0) return 0;
  return sum + (s.start - arr[i-1].end);
}, 0) / segments.length;

return {
  transcript: $input.item.json.text,
  agent_speaker: agentSpeaker,
  customer_speaker: customerSpeaker,
  talk_ratio: talkRatio.toFixed(2),
  call_duration_seconds: callDuration,
  avg_pause_seconds: avgPause.toFixed(2),
  total_segments: segments.length
};

// 5. HTTP-Request - Sentiment-Analyse (OpenAI)
Methode: POST
URL: http://open-webui:8080/api/chat/completions
Body: {
  "model": "gpt-4o-mini",
  "messages": [{
    "role": "system",
    "content": "Analysiere diesen Kundensupport-Anruf und bewerte: Kundenzufriedenheit (1-10), Probleml√∂sung (ja/nein), Agent-Leistung (1-10), Hauptprobleme, Empfehlungen"
  }, {
    "role": "user",
    "content": "{{ $json.transcript }}"
  }]
}

// 6. IF-Node - Pr√ºfe ob Eskalation erforderlich
If: {{ $json.customer_satisfaction < 5 }} OR {{ $json.issue_resolved === false }}

// 7a. Slack-Node - Manager alarmieren
Kanal: #support-escalations
Nachricht: |
  ‚ö†Ô∏è Anruf erfordert √úberpr√ºfung
  
  **Anrufdauer:** {{ $json.call_duration_seconds }}s
  **Kundenzufriedenheit:** {{ $json.customer_satisfaction }}/10
  **Problem gel√∂st:** {{ $json.issue_resolved }}
  **Hauptprobleme:** {{ $json.key_issues }}
  
  **Empfehlungen:** {{ $json.recommendations }}

// 7b. Datenbank - Anruf-Analysen speichern
// Metriken f√ºr Reporting-Dashboard einf√ºgen
```

### Fehlerbehebung

**Problem 1: Erste Transkription dauert ewig**

```bash
# Modell wird bei erster Nutzung heruntergeladen - das ist normal
docker logs scriberr --tail 100

# Du wirst Modell-Download-Fortschritt sehen:
# Downloading WhisperX model: base
# Progress: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%

# Speicherplatz pr√ºfen
df -h

# Modelle ben√∂tigen:
# tiny: ~40MB
# base: ~145MB
# small: ~466MB
# medium: ~1,5GB
# large: ~6GB
```

**L√∂sung:**
- Erste Transkription mit neuem Modell dauert 2-30 Minuten (Modell-Download)
- Nachfolgende Transkriptionen sind schnell (Modell gecacht)
- Modelle vorab herunterladen durch Test-Transkription nach Installation
- Ausreichenden Speicherplatz f√ºr Modelle sicherstellen

**Problem 2: Sprecher-Diarisierung funktioniert nicht**

```bash
# Sprechererkennungseinstellungen in API-Anfrage pr√ºfen
# Verifiziere dass min_speakers und max_speakers korrekt gesetzt sind

# Scriberr-Logs pr√ºfen
docker logs scriberr | grep -i "speaker\|diarization"

# H√§ufige Probleme:
# - Audio zu kurz (< 30 Sekunden)
# - Nur ein Sprecher im Audio
# - Schlechte Audioqualit√§t (Hintergrundger√§usche)
# - min_speakers > tats√§chliche Sprecher
```

**L√∂sung:**
- Audio muss mindestens 30 Sekunden f√ºr Diarisierung sein
- Setze realistische min/max Sprecherbereich (2-4 typisch)
- Stelle klares Audio mit deutlichen Sprechern bereit
- Verwende Mono-Audio (Stereo kann Diarisierung verwirren)
- Sprecher-Labels sind generisch (SPEAKER_00, SPEAKER_01) - bei Bedarf manuell umbenennen

**Problem 3: YouTube-Transkription schl√§gt fehl**

```bash
# Scriberr-Logs pr√ºfen
docker logs scriberr --tail 50

# H√§ufige Fehler:
# - "Video unavailable" ‚Üí Privates/eingeschr√§nktes Video
# - "Network timeout" ‚Üí Video zu lang
# - "Format not supported" ‚Üí Altersbeschr√§nkter Inhalt
```

**L√∂sung:**
- Verwende nur √∂ffentliche, nicht eingeschr√§nkte YouTube-Videos
- F√ºr lange Videos (>2 Stunden), separat herunterladen und hochladen
- Pr√ºfe dass YouTube-URL korrektes Format hat: `https://youtube.com/watch?v=...`
- Manche Unternehmensnetzwerke blockieren YouTube-Downloads - in anderem Netzwerk testen

**Problem 4: Speicherfehler**

```bash
# Container-Speichernutzung pr√ºfen
docker stats scriberr --no-stream

# Server-RAM pr√ºfen
free -h

# Scriberr-Speicheranforderungen:
# tiny Modell: ~1GB RAM
# base Modell: ~1,5GB RAM
# small Modell: ~3GB RAM
# medium Modell: ~5GB RAM
# large Modell: ~10GB RAM

# Docker-Container-Limits pr√ºfen
docker inspect scriberr | grep -i memory
```

**L√∂sung:**
- Kleineres Modell verwenden (base statt large)
- K√ºrzere Audiodateien verarbeiten (<30 Minuten)
- Lange Dateien vor Upload aufteilen
- Docker-Speicherlimits in docker-compose.yml erh√∂hen
- Sicherstellen dass keine anderen schweren Dienste gleichzeitig laufen

**Problem 5: KI-Zusammenfassungsgenerierung schl√§gt fehl**

```bash
# Pr√ºfen ob OpenAI/Anthropic API-Schl√ºssel konfiguriert ist
docker exec scriberr env | grep -i "api_key\|openai\|anthropic"

# Scriberr-Summary-Endpunkt pr√ºfen
docker logs scriberr | grep -i "summary\|openai\|anthropic"
```

**L√∂sung:**
- OpenAI- oder Anthropic-API-Schl√ºssel in Scriberr-Einstellungen konfigurieren
- Oder lokales LLM √ºber Open WebUI f√ºr Zusammenfassungen verwenden
- Summary-Endpunkt ben√∂tigt transcript_id von abgeschlossener Transkription
- Ausreichend API-Guthaben verf√ºgbar sicherstellen
- F√ºr Datenschutz, lokales LLM statt externer APIs verwenden

### Tipps f√ºr beste Ergebnisse

**Audioqualit√§t ist wichtig:**
1. **Verwende hochwertige Aufnahmen:** WAV- oder FLAC-Format bevorzugt
2. **Mindestens 16kHz Abtastrate:** H√∂her ist besser (44,1kHz ideal)
3. **Klare, frontale Mikrofone:** Ansteckmikrofone oder gute USB-Mikrofone
4. **Hintergrundger√§usche minimieren:** Ruhiger Raum, T√ºren schlie√üen, L√ºfter ausschalten
5. **Kompression vermeiden:** Unkomprimiertes Audio hochladen wenn m√∂glich

**Sprecher-Diarisierungs-Tipps:**
1. **Setze realistische Sprecheranzahl:** Die meisten Meetings haben 2-6 Sprecher
2. **Deutliche Sprecher:** Physische Trennung hilft bei Identifikation
3. **√úberlappende Sprache vermeiden:** Auf Pausen zwischen Sprechern warten
4. **L√§ngeres Audio = bessere Genauigkeit:** 5+ Minuten empfohlen
5. **Sprecher manuell kennzeichnen:** SPEAKER_00 ‚Üí "Max Mustermann" in Nachbearbeitung

**Verarbeitungszeit-Optimierung:**
1. **W√§hle richtiges Modell f√ºr Aufgabe:**
   - Entwicklung/Testing: tiny oder base
   - Produktion: small oder medium
   - Genauigkeitskritisch: large
2. **Audio vorverarbeiten:** Stille entfernen, Lautst√§rke normalisieren
3. **Lange Dateien aufteilen:** <30 Minuten pro Datei f√ºr schnellere Verarbeitung
4. **Batch-Verarbeitung:** Mehrere Dateien w√§hrend Nebenzeiten in Warteschlange

**Integrations-Best-Practices:**
1. **Verwende Polling f√ºr lange Transkriptionen:** Status alle 30-60 Sekunden pr√ºfen
2. **Fehler elegant behandeln:** Bei Netzwerkfehlern wiederholen
3. **Ergebnisse cachen:** Transkripte in Datenbank speichern um Neuverarbeitung zu vermeiden
4. **Webhook-Unterst√ºtzung:** Callbacks f√ºr asynchrone Verarbeitung konfigurieren
5. **Rate-Limiting:** Nicht mit simultanen Anfragen √ºberlasten

### Ressourcen

- **GitHub:** https://github.com/rishikanthc/Scriberr
- **WhisperX Paper:** https://arxiv.org/abs/2303.00747
- **API-Dokumentation:** Verf√ºgbar unter `http://scriberr:8080/docs` (wenn laufend)
- **Sprecher-Diarisierungs-Leitfaden:** https://github.com/pyannote/pyannote-audio
- **Modellvergleich:** https://github.com/openai/whisper#available-models-and-languages
- **Sprachunterst√ºtzung:** 99 Sprachen unterst√ºtzt von Whisper

### Wann Scriberr verwenden

**‚úÖ Perfekt f√ºr:**
- Meeting-Aufzeichnungen mit mehreren Sprechern
- Podcast-Episode-Transkription
- Interview-Analyse
- Kundensupport-Anruf-Qualit√§tssicherung
- Rechtliche Aussagen und Gerichtsaufzeichnungen
- Fokusgruppen-Analyse
- Medizinische Konsultationen (mit entsprechender Einwilligung)
- Akademische Forschungsinterviews
- Konferenzvortrag-Transkription

**‚ùå Nicht ideal f√ºr:**
- Echtzeit-Live-Transkription (verwende stattdessen Vexa)
- Einzelsprecher mit Echtzeitanforderungen (verwende Faster-Whisper)
- Sehr kurze Audio-Clips (<10 Sekunden)
- Stark √ºberlappende Sprache
- Extrem laute Umgebungen
- Musik-Transkription (nicht daf√ºr konzipiert)

**Scriberr vs Faster-Whisper vs Vexa:**
- **Scriberr:** Am besten f√ºr Sprecher-Diarisierung, asynchrone Verarbeitung, detaillierte Transkripte
- **Faster-Whisper:** Am besten f√ºr Geschwindigkeit, Echtzeit-Apps, Einzelsprecher
- **Vexa:** Am besten f√ºr Live-Meeting-Transkription (Google Meet, Teams)
